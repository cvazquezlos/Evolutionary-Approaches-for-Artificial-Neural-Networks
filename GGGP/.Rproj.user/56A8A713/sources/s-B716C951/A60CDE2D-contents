library("xlsx")
library("ggplot2")
library("sets")
library("keras")
library("stringr")
#install.packages("xlsx")

# setwd("D:/Usuarios/cvazquezlos/GitHub/Genetic-programming-for-Artificial-Neural-Networks/results")
setwd("~/GitHub/Evolutionary-Approaches-for-Artificial-Neural-Networks/results")

TARGET_FOLDER <- "./classification/ocean_proximity/total/"

BASE_DATA_FRAME <- data.frame(execution = integer(),
                              architecture = character(),
                              partial_acc_train = double(),
                              partial_acc_validation = double(),
                              partial_acc_test = double(),
                              time = double(),
                              saved_model = character(),
                              total_acc_train = double(),
                              total_acc_validation = double(),
                              total_acc_test = double(),
                              stringsAsFactors = FALSE)
executions <- list.files(TARGET_FOLDER)

bad_executions <- list()
executions_results <- BASE_DATA_FRAME
y <- lapply(executions, function (x) {
  tryCatch({
    df = readRDS(paste0(TARGET_FOLDER, "/", x, "/final_population.rds"))
    executions_results <<- rbind(executions_results, df)
  }, error = function(cond) {
    bad_executions <<- c(bad_executions, x)
  }, warning = function(cond) {
    bad_executions <<- c(bad_executions, x)
  })
})
rm("y")
# Repairing task of the executions.
bad_executions <- unlist(bad_executions)
for (bad_execution in bad_executions) {
  individual_histories <- list.files(paste0(TARGET_FOLDER, "/", bad_execution, "/history"))
  individual_ranking <- data.frame(individual = character(), 
                                   acc_train = numeric(), 
                                   acc_validation = numeric(),
                                   numeric(), stringsAsFactors = FALSE)
  for (history in individual_histories) {
    aux <- readRDS(paste0(TARGET_FOLDER, "/", bad_execution, "/history/", history))
    ranking_tr <- aux[aux$metric == "acc" & aux$data == "training",]
    ranking_tr<- ranking_tr[order(ranking_tr$value, decreasing = TRUE),]
    ranking_val <- aux[aux$metric == "acc" & aux$data == "validation",]
    ranking_val<- ranking_val[order(ranking_val$value, decreasing = TRUE),]
    individual_ranking <- rbind(individual_ranking, data.frame(individual = history, acc_train = ranking_tr[1,]$value,
                                                               acc_validation = ranking_val[1,]$value))
  }
  individual_ranking <- individual_ranking[order(individual_ranking$acc_train, decreasing = TRUE),]
  saveRDS(individual_ranking[1,], paste0(TARGET_FOLDER, "/", bad_execution, "/", "execution_results.rds"))
}

for (bad_execution in bad_executions) {
  individual <- readRDS(paste0(TARGET_FOLDER, "/", bad_execution, "/", "execution_results.rds"))
  colnames(individual) <- c("architecture", "acc_train", "acc_validation")
  individual$saved_model <- individual$architecture
  ind_name <- str_replace_all(individual$architecture, ".rds", "")
  model <- load_model_hdf5(paste0(TARGET_FOLDER, "/", bad_execution, "/model/", ind_name, ".h5"))
  individual$acc_test <- (model %>% evaluate(X_test, y_test))['acc'][[1]]
  individual$architecture <- gsub("-.*", "", individual$architecture)
  saveRDS(individual, paste0(TARGET_FOLDER, "/", bad_execution, "/", "execution_results1.rds"))
}
library("caret")
library("cowplot")
library("dummies")
library("ggplot2")
library("gramEvol")
library("jsonlite")
library("keras")
# install_keras(tensorflow = "gpu", method = "conda")
# install_keras()
library("sqldf")
library("stringr")
# install.packages("dummies")
# install.packages("ggplot2")
# install.packages("gramEvol")
# install.packages("jsonlite")
# install.packages("keras")
# install.packages("sqldf")
# install.packages("stringr")

setwd("~/GitHub/Evolutionary-Approaches-for-Artificial-Neural-Networks/GGGP")
# setwd("D:/Usuarios/cvazquezlos/GitHub/Genetic-programming-for-Artificial-Neural-Networks/GGGP")
rm(list=ls())

GRAMMAR <- list(
  S = gsrule("<a><h>/<z>"),
  a = grule("nnnn"), # Update a with many n as value of I.
  z = grule("nnn"),  # Update z with many n as value of O.
  h = gsrule("<h><h>", "<h><h>", "/<n>"),
  n = gsrule("n<n>", "n")
)
I <- NA
p <- 20
O <- NA

base_architecture <- data.frame(id = rep(NA, p), architecture = rep(NA, p), 
                                evaluated = rep(NA, p), loss = rep(NA, p), 
                                metric = rep(NA, p), saved_model = rep(NA, p), 
                                stringsAsFactors = FALSE)

##################### EVOLUTIONARY  OPERATORS #####################
generation <- function() {
  architectures <- GrammarRandomExpression(CreateGrammar(GRAMMAR), p)
  i <- 1
  population <- base_architecture
  for (individual in architectures) {
    population[i,] <- c(id, toString(gsub("\"", "", toString(individual))), 
                        FALSE, NA, NA, NA)
    i <- i + 1
    id <<- id + 1
  }
  return(population)
}

evaluation <- function(individual, split_crit, mode) {
  # Neurons extraction
  hidden_layers <- numeric(0)
  i <- 0
  if (split_crit == 0) {
    splitting <- head(strsplit(individual$architecture[[1]], "/")[[1]], -1)
  } else {
    splitting <- head(strsplit(toString(individual$architecture), "/")[[1]], -1)
  }
  for (layer in splitting) {
    if (i != 0) {
      hidden_layers[i] <- nchar(layer)
    }
    i <- i + 1
  }
  # Individual evaluation
  model <- keras_model_sequential()
  model %>% layer_dense(units = hidden_layers[1], input_shape = c(I), 
                        activation = "relu")
  for (layer in tail(hidden_layers, 1)) {
    model %>% layer_dense(units = layer, activation = "relu")
  }
  model %>% layer_dense(units = O, activation = "softmax")
  model %>% compile(
    optimizer = "adam",
    loss = "categorical_crossentropy",
    metrics = c("accuracy")
  )
  history <- model %>% fit(rbind(X_train, X_validation), rbind(y_train, y_validation), 
                           validation_split = 0.235294, epochs = 300, batch_size = 250,
                           verbose = 0, callbacks = list(
                             callback_early_stopping(monitor = "val_loss", patience = 50, 
                                                     verbose = 0, mode ="auto")
                           ))
  model_name <- paste0(str_replace_all(individual$architecture, "/", "_"), "-", 
                       individual$id)
  history_df <- as.data.frame(history)
  saveRDS(history_df, file = paste0("data/", execution, "/history/", model_name, ".rds"))
  save_model_hdf5(model, paste0("data/", execution, "/model/", model_name, ".h5"))
  score <- model %>% evaluate(X_train, y_train)
  individual$evaluated <- TRUE
  individual$loss <- score['loss'][[1]]
  individual$metric <- score['acc'][[1]]
  individual$saved_model <- model_name
  return(individual)
}

selection <- function(no_childs) {
  no_parents <- no_childs
  matting_pool <- data.frame()
  for (j in c(1:(no_childs/2))) {
    parents_sample <- population[sample(nrow(population), no_childs/2),]
    ordered_parents_sample <- parents_sample[order(unlist(parents_sample$loss)),]
    matting_pool <- rbind(matting_pool, head(ordered_parents_sample, 2))
  }
  return(matting_pool)
}

crossover <- function(parents) {
  s_p1_parts <- extract_hidden_layers(parents$architecture[[1]])
  s_p2_parts <- extract_hidden_layers(parents$architecture[[2]])
  random_s_p1 <- sample(s_p1_parts, 1)
  random_s_p2 <- sample(s_p2_parts, 1)
  s_p1_parts <- lapply(s_p1_parts, function(x) {if(x==random_s_p1) {random_s_p2} else {x}})
  s_p2_parts <- lapply(s_p2_parts, function(x) {if(x==random_s_p2) {random_s_p1} else {x}})
  df <- data.frame(id = integer(),
                   architecture = character(),
                   evaluated = logical(),
                   loss = double(),
                   metric = double(),
                   saved_model = character(),
                   stringsAsFactors = FALSE)
  df <- rbind(df, data.frame(id = id, 
                             architecture = toString(add_inout_layers(s_p1_parts)), 
                             evaluated = FALSE, loss = NA, metric = NA, saved_model = NA))
  id <<- id + 1
  df <- rbind(df, data.frame(id = id, 
                             architecture = toString(add_inout_layers(s_p2_parts)), 
                             evaluated = FALSE, loss = NA, metric = NA, saved_model = NA))
  id <<- id + 1
  return(df)
}

replacement <- function(children) {
  max_population <- rbind(population, children)
  ordered_max_population <- max_population[order(unlist(max_population$loss)),]
  return(ordered_max_population[c(1:p),])
}

##################### AUXILIARY FUNCTIONS #####################
add_inout_layers <- function(hidden) {
  return(paste(strrep("n", I), "/", paste0(hidden, collapse = "/"), "/", 
               strrep("n", O), sep = ""))
}

extract_hidden_layers <- function(architecture) {
  split <- strsplit(architecture, split = "/")
  return(tail(head(split[[1]], -1), -1))
}

###########################################################
##################### MAIN  ALGORITHM #####################
###########################################################
data <- read.csv2("../datasets/classification/ocean_proximity.csv", sep = ";")
# ONE HOT ENCODING
# dummy_data <- dummyVars(" ~ class", data = data)
# trsf <- data.frame(predict(dummy_data, newdata = data), stringsAsFactors = F)
# trsf$sepal_length <- as.numeric(as.character(data$sepal_length))
# trsf$sepal_width <- as.numeric(as.character(data$sepal_width))
# trsf$petal_length <- as.numeric(as.character(data$petal_length))
# trsf$petal_width <- as.numeric(as.character(data$petal_width))
# data <- trsf[,c(4:7,1:3)]
# data$sepal_length <- (data$sepal_length - min(data$sepal_length))/(max(data$sepal_length)-min(data$sepal_length))
# data$sepal_width <- (data$sepal_width - min(data$sepal_width))/(max(data$sepal_width)-min(data$sepal_width))
# data$petal_length <- (data$petal_length - min(data$petal_length))/(max(data$petal_length)-min(data$petal_length))
# data$petal_width <- (data$petal_width - min(data$petal_width))/(max(data$petal_width)-min(data$petal_width))

n <- nrow(data)
set.seed(123)
shuffled_df <- as.data.frame(data[sample(n),])
colnames(shuffled_df) <- gsub("[^a-zA-Z]*", "", colnames(shuffled_df))
train <- shuffled_df[1: round(0.7*n),]
validation <- shuffled_df[(round(0.7*n)+1):round(0.9*n),]
test <- shuffled_df[(round(0.9*n)+1):n,]
X_train <- train[,head(colnames(shuffled_df), -4)] %>% as.matrix()
y_train <- train[,tail(colnames(shuffled_df), 4)] %>% as.matrix()
X_validation <- validation[,head(colnames(shuffled_df), -4)] %>% as.matrix()
y_validation <- validation[,tail(colnames(shuffled_df), 4)] %>% as.matrix()
X_test <- test[,head(colnames(shuffled_df), -4)] %>% as.matrix()
y_test <- test[,tail(colnames(shuffled_df), 4)] %>% as.matrix()
I <- length(colnames(X_train))
O <- length(colnames(y_train))

executions <- c(8:80)
repeat_executions <- c()
for (execution in executions) {
  tryCatch({
    execution_results <- data.frame(execution = integer(),
                                    architecture = character(),
                                    acc_train = numeric(),
                                    acc_validation = numeric(),
                                    acc_test = numeric(),
                                    time = numeric(),
                                    saved_model = character(),
                                    stringsAsFactors = F)
    start_time = Sys.time()
    id <- 1
    iteration_results <- data.frame(iteration = integer(),
                                    avg_loss = numeric(),
                                    best_loss = numeric(),
                                    stringsAsFactors = T)
    dir.create(paste0("data/", execution), showWarnings = F)
    dir.create(paste0("data/", execution, "/history"), showWarnings = F)
    dir.create(paste0("data/", execution, "/model"), showWarnings = F)
    # Generation
    population <- generation()
    # Evaluation
    for (individual in 1:nrow(population)) {
      population[individual,] = evaluation(population[individual,], 0, 0)
    }
    iteration <- 1
    while (T) {
      k_clear_session()
      # Stop condition
      results <- sqldf("select * from population where metric >= 0.985 order by id")
      if ((nrow(results) != 0) | (length(unique(population$architecture)) == 1)) {
        solution <- results[1,]
        break
      } else if (iteration == 30) {
        solution <- results[1,]
        break
      } else {
        # Selection
        matting_pool <- selection(6)
        # Crossover
        children <- data.frame(id = integer(),
                               architecture = character(),
                               evaluated = logical(),
                               loss = numeric(),
                               metric = numeric(),
                               saved_model = character(),
                               stringsAsFactors = FALSE)
        for (i in c(1:(nrow(matting_pool)/2))) {
          j <- (i*2)-1
          children <- rbind(children, crossover(matting_pool[c(j:(j+1)),]))
        }
        # Evaluation
        for (individual in 1:nrow(children)) {
          children[individual,] = evaluation(children[individual,], 1, 0)
        }
        # Replacement
        population <- replacement(children)
        population <- population[order(unlist(population$id)),]
      }
      iteration_results <- rbind(iteration_results, 
                                 data.frame(iteration = iteration, 
                                            avg_loss = ((Reduce("+", as.numeric(population$loss))) / p),
                                            best_loss = population[which.min(population$loss), 4]))
      iteration <- iteration + 1
    }
    saveRDS(population, file = paste0("data/", execution, "/final_population.rds"))
    saveRDS(iteration_results, file = paste0("data/", execution, "/", execution, "_results.rds"))
    model <- load_model_hdf5(paste0("data/", execution, "/model/", solution$saved_model, ".h5"))
    acc_train <- (model %>% evaluate(X_train, y_train))['acc'][[1]]
    acc_validation <- (model %>% evaluate(X_validation, y_validation))['acc'][[1]]
    acc_test <- (model %>% evaluate(X_test, y_test))['acc'][[1]]
    end_time = Sys.time()
    # Ejecuar a partir de aqu?
    iteration_results$avg_loss <- as.numeric(iteration_results$avg_loss)
    iteration_results$best_loss <- as.numeric(as.character(iteration_results$best_loss))
    execution_results <- rbind(execution_results, data.frame(execution = execution, 
                                                             architecture = solution$architecture,
                                                             acc_train = acc_train,
                                                             acc_validation = acc_validation,
                                                             acc_test = acc_test,
                                                             time = as.double(toString(end_time - start_time)),
                                                             saved_model = solution$saved_model))
    saveRDS(execution_results, file = paste0("data/", execution, "/execution_results.rds"))
  }, error = function(e){
    print(e)
    repeat_executions <<- c(repeat_executions, execution)
  })
  k_clear_session()
}
EXECUTIONS_DIRECTORY <- "../results/classification/iris/partial/"
executions <- list.files(EXECUTIONS_DIRECTORY)
executions <- as.numeric(executions[!is.na(as.numeric(executions))])
aux = c(1:80)
remaining <- unlist(lapply(aux, function(x) if (!(x %in% executions)) TRUE else FALSE))
bad_executions <- aux[remaining]

# Only for partial executions
for (execution in executions) {
  path = paste0("../results/classification/iris/partial/", execution)
  results <- readRDS(paste0(path, "/execution_results.rds"))
  results <- results[,c(1:3,5,4)]
  results$saved_model <- str_replace_all(results$saved_model, ".rds", "")
  model <- load_model_hdf5(paste0(path, "/model/", results$saved_model, ".h5"))
  model %>% fit(rbind(X_train, X_validation), rbind(y_train, y_validation), validation_split = 0.235294, epochs = 450, verbose = 0,
                callbacks = list(
                  callback_early_stopping(monitor = "val_loss", patience = 50, verbose = 0, mode ="auto")
                ))
  colnames(results) <- c("architecture", "partial_acc_train", "partial_acc_validation", "partial_acc_test", "saved_model")
  results$total_acc_train <- (model %>% evaluate(X_train, y_train))['acc'][[1]]
  results$total_acc_validation <- (model %>% evaluate(X_validation, y_validation))['acc'][[1]]
  results$total_acc_test <- (model %>% evaluate(X_test, y_test))['acc'][[1]]
  saveRDS(results, paste0(path, "/execution_results.rds"))
  k_clear_session()
}

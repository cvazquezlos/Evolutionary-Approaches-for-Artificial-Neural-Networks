test_data <- NULL
train <- NULL      #70%
validation <- NULL #20%
test <- NULL       #10%
input <- NULL
output <- NULL
data_cleaning <- function(url, sep){
data <<- read.csv(url, header=T, sep=sep)
validation_data <<- data[(round(0.7*n)+1):round(0.9*n),]
test_data <<- data[(round(0.9*n)+1):n,]
colnames(data) <- gsub("[^a-zA-Z]*", "", colnames(data))
input <<- paste(head(colnames(data),-1), collapse="+")
output <<- paste(tail(colnames(data),1))
n <- nrow(data)
max <- apply(data, 2, max)
min <- apply(data, 2, min)
scaled_data <- scale(data, center=min, scale=max-min) # Normalization for numeric datasets.
shuffled_df <- as.data.frame(scaled_data[sample(n),])
train <<- shuffled_df[1:round(0.7*n),]
validation <<-  shuffled_df[(round(0.7*n)+1):round(0.9*n),]
test <<- shuffled_df[(round(0.9*n)+1):n,]
}
data_cleaning("./cereals.csv", ",")
extract_neurons <- function(word) {
layers <- strsplit(word, "/")[[1]]
i <- 0
hidden_l <- numeric(0) # Contains the number of hidden layers and the number of neurons of each hidden layer.
for(j in head(layers, -1)) {
if (i!=0) {hidden_l[i] <- nchar(j)}
i <- i+1
}
return(hidden_l)
}
# https://www.analyticsvidhya.com/blog/2017/09/creating-visualizing-neural-network-in-r/
evaluation <- function(word) {
hidden_layers <- extract_neurons(word)
# https://www.rdocumentation.org/packages/neuralnet/versions/1.33/topics/neuralnet PARAMETERS
nn <- neuralnet(paste(output,input,sep="~"), data=train, hidden=hidden_layers, linear.output=T)
plot(nn)
nn$result.matrix
fitness <- compute(nn, validation[,c(1:(length(colnames(train))-1))])
fitness <- (fitness$net.result * (max(data[output]) - min(data[output]))) + min(data[output])
plot(validation_data$ratng, fitness, col='blue', pch=16, ylab="predicted rating", xlab="real rating")
RME <- (sum((validation_data[output] - fitness)/nrow(validation_data)))^0.5
return(fitness)
}
evaluation("nnnn/nnnn/n")
library("gramEvol")
library("neuralnet")
data <- NULL
validation_data <- NULL
test_data <- NULL
train <- NULL      #70%
validation <- NULL #20%
test <- NULL       #10%
input <- NULL
output <- NULL
data_cleaning <- function(url, sep){
data <<- read.csv(url, header=T, sep=sep)
n <- nrow(data)
validation_data <<- data[(round(0.7*n)+1):round(0.9*n),]
test_data <<- data[(round(0.9*n)+1):n,]
colnames(data) <- gsub("[^a-zA-Z]*", "", colnames(data))
input <<- paste(head(colnames(data),-1), collapse="+")
output <<- paste(tail(colnames(data),1))
max <- apply(data, 2, max)
min <- apply(data, 2, min)
scaled_data <- scale(data, center=min, scale=max-min) # Normalization for numeric datasets.
shuffled_df <- as.data.frame(scaled_data[sample(n),])
train <<- shuffled_df[1:round(0.7*n),]
validation <<-  shuffled_df[(round(0.7*n)+1):round(0.9*n),]
test <<- shuffled_df[(round(0.9*n)+1):n,]
}
data_cleaning("./cereals.csv", ",")
extract_neurons <- function(word) {
layers <- strsplit(word, "/")[[1]]
i <- 0
hidden_l <- numeric(0) # Contains the number of hidden layers and the number of neurons of each hidden layer.
for(j in head(layers, -1)) {
if (i!=0) {hidden_l[i] <- nchar(j)}
i <- i+1
}
return(hidden_l)
}
# https://www.analyticsvidhya.com/blog/2017/09/creating-visualizing-neural-network-in-r/
evaluation <- function(word) {
hidden_layers <- extract_neurons(word)
# https://www.rdocumentation.org/packages/neuralnet/versions/1.33/topics/neuralnet PARAMETERS
nn <- neuralnet(paste(output,input,sep="~"), data=train, hidden=hidden_layers, linear.output=T)
plot(nn)
nn$result.matrix
fitness <- compute(nn, validation[,c(1:(length(colnames(train))-1))])
fitness <- (fitness$net.result * (max(data[output]) - min(data[output]))) + min(data[output])
plot(validation_data$ratng, fitness, col='blue', pch=16, ylab="predicted rating", xlab="real rating")
RME <- (sum((validation_data[output] - fitness)/nrow(validation_data)))^0.5
return(fitness)
}
evaluation("nnnn/nnnn/n")
# https://www.analyticsvidhya.com/blog/2017/09/creating-visualizing-neural-network-in-r/
evaluation <- function(word) {
hidden_layers <- extract_neurons(word)
# https://www.rdocumentation.org/packages/neuralnet/versions/1.33/topics/neuralnet PARAMETERS
nn <- neuralnet(paste(output,input,sep="~"), data=train, hidden=hidden_layers, linear.output=T)
plot(nn)
fitness <- compute(nn, validation[,c(1:(length(colnames(validation_data))-1))])
fitness <- (fitness$net.result * (max(data[output]) - min(data[output]))) + min(data[output])
plot(validation_data$ratng, fitness, col='blue', pch=16, ylab="predicted rating", xlab="real rating")
RME <- (sum((validation_data[output] - fitness)/nrow(validation_data)))^0.5
return(fitness)
}
evaluation("nnnn/nnnn/n")
# https://www.analyticsvidhya.com/blog/2017/09/creating-visualizing-neural-network-in-r/
evaluation <- function(word) {
hidden_layers <- extract_neurons(word)
# https://www.rdocumentation.org/packages/neuralnet/versions/1.33/topics/neuralnet PARAMETERS
nn <- neuralnet(paste(output,input,sep="~"), data=train, hidden=hidden_layers, linear.output=T)
plot(nn)
fitness <- compute(nn, validation[,c(1:(length(colnames(validation_data))-1))])
fitness <- (fitness$net.result * (max(data[output]) - min(data[output]))) + min(data[output])
plot(validation_data$ratng, fitness, col='blue', pch=16, ylab="predicted rating", xlab="real rating")
RME <- (sum((validation_data[output]-fitness)^2)/nrow(validation_data)))^0.5
return(fitness)
}
evaluation("nnnn/nnnn/n")
evaluation <- function(word) {
hidden_layers <- extract_neurons(word)
# https://www.rdocumentation.org/packages/neuralnet/versions/1.33/topics/neuralnet PARAMETERS
nn <- neuralnet(paste(output,input,sep="~"), data=train, hidden=hidden_layers, linear.output=T)
fitness <- compute(nn, validation[,c(1:(length(colnames(validation_data))-1))])
fitness <- (fitness$net.result * (max(data[output]) - min(data[output]))) + min(data[output])
plot(validation_data$ratng, fitness, col='blue', pch=16, ylab="predicted rating", xlab="real rating")
return(fitness)
}
evaluation("nnnn/nnnn/n")
length(colnames(validation))
evaluation <- function(word) {
hidden_layers <- extract_neurons(word)
# https://www.rdocumentation.org/packages/neuralnet/versions/1.33/topics/neuralnet PARAMETERS
nn <- neuralnet(paste(output,input,sep="~"), data=train, hidden=hidden_layers, linear.output=T)
fitness <- compute(nn, validation[,c(1:(length(colnames(validation))-1))])
fitness <- (fitness$net.result * (max(data[output]) - min(data[output]))) + min(data[output])
plot(validation_data[output], fitness, col='blue', pch=16, ylab="predicted rating NN", xlab="real rating")
abline(0,1)
return(fitness)
}
evaluation("nnnn/nnnn/n")
evaluation <- function(word) {
hidden_layers <- extract_neurons(word)
# https://www.rdocumentation.org/packages/neuralnet/versions/1.33/topics/neuralnet PARAMETERS
nn <- neuralnet(paste(output,input,sep="~"), data=train, hidden=hidden_layers, linear.output=T)
fitness <- compute(nn, validation[,c(1:(length(colnames(validation))-1))])
fitness <- (fitness$net.result * (max(data[output]) - min(data[output]))) + min(data[output])
plot(validation_data[output], fitness, col='blue', pch=16, ylab="predicted rating NN", xlab="real rating")
abline(0,1)
return(fitness)
}
evaluation("nnnn/nnnn/n")
typeof(fitness)
evaluation <- function(word) {
hidden_layers <- extract_neurons(word)
# https://www.rdocumentation.org/packages/neuralnet/versions/1.33/topics/neuralnet PARAMETERS
nn <- neuralnet(paste(output,input,sep="~"), data=train, hidden=hidden_layers, linear.output=T)
fitness <- compute(nn, validation[,c(1:(length(colnames(validation))-1))])
fitness <- (fitness$net.result * (max(data[output]) - min(data[output]))) + min(data[output])
print(typeof(fitness))
print(typeof(validation_data[output]))
plot(validation_data[output], fitness, col='blue', pch=16, ylab="predicted rating NN", xlab="real rating")
abline(0,1)
return(fitness)
}
evaluation("nnnn/nnnn/n")
# https://www.analyticsvidhya.com/blog/2017/09/creating-visualizing-neural-network-in-r/
evaluation <- function(word) {
hidden_layers <- extract_neurons(word)
# https://www.rdocumentation.org/packages/neuralnet/versions/1.33/topics/neuralnet PARAMETERS
nn <- neuralnet(paste(output,input,sep="~"), data=train, hidden=hidden_layers, linear.output=T)
fitness <- compute(nn, validation[,c(1:(length(colnames(validation))-1))])
#fitness <- (fitness$net.result * (max(data[output]) - min(data[output]))) + min(data[output])
print(typeof(fitness))
print(typeof(validation_data[output]))
plot(validation_data[output], fitness, col='blue', pch=16, ylab="predicted rating NN", xlab="real rating")
abline(0,1)
return(fitness)
}
evaluation("nnnn/nnnn/n")
data[output]
evaluation <- function(word) {
hidden_layers <- extract_neurons(word)
# https://www.rdocumentation.org/packages/neuralnet/versions/1.33/topics/neuralnet PARAMETERS
nn <- neuralnet(paste(output,input,sep="~"), data=train, hidden=hidden_layers, linear.output=T)
# https://gist.github.com/abresler/d2c324b44d7319b58309 VALIDATION
validation_prediction <- compute(nn, validation[,c(1:(length(colnames(validation))-1))])
validation_prediction_l <- validation_prediction$net.result*(max(data[output])-min(data[output]))+min(data[output])
fitness <- (sum(validation_prediction_l - validation_prediction)^2)/nrow(validation)
return(fitness)
}
evaluation("nnnn/nnnn/n")
evaluation <- function(word) {
hidden_layers <- extract_neurons(word)
# https://www.rdocumentation.org/packages/neuralnet/versions/1.33/topics/neuralnet PARAMETERS
nn <- neuralnet(paste(output,input,sep="~"), data=train, hidden=hidden_layers, linear.output=T)
# https://gist.github.com/abresler/d2c324b44d7319b58309 VALIDATION
validation_prediction <- compute(nn, validation[,c(1:(length(colnames(validation))-1))])
validation_prediction_l <- validation_prediction$net.result*(max(data[output])-min(data[output]))+min(data[output])
results <- (validation[output])*(max(data[output])-min(data[output]))+min(data[output])
fitness <- (sum(result - validation_prediction_l)^2)/nrow(validation)
return(fitness)
}
evaluation("nnnn/nnnn/n")
evaluation <- function(word) {
hidden_layers <- extract_neurons(word)
# https://www.rdocumentation.org/packages/neuralnet/versions/1.33/topics/neuralnet PARAMETERS
nn <- neuralnet(paste(output,input,sep="~"), data=train, hidden=hidden_layers, linear.output=T)
# https://gist.github.com/abresler/d2c324b44d7319b58309 VALIDATION
validation_prediction <- compute(nn, validation[,c(1:(length(colnames(validation))-1))])
validation_prediction_l <- validation_prediction$net.result*(max(data[output])-min(data[output]))+min(data[output])
results <- (validation[output])*(max(data[output])-min(data[output]))+min(data[output])
fitness <- (sum(results - validation_prediction_l)^2)/nrow(validation)
return(fitness)
}
evaluation("nnnn/nnnn/n")
# https://www.analyticsvidhya.com/blog/2017/09/creating-visualizing-neural-network-in-r/
evaluation <- function(word) {
hidden_layers <- extract_neurons(word)
# https://www.rdocumentation.org/packages/neuralnet/versions/1.33/topics/neuralnet PARAMETERS
nn <- neuralnet(paste(output,input,sep="~"), data=train, hidden=hidden_layers, linear.output=T)
# https://gist.github.com/abresler/d2c324b44d7319b58309 VALIDATION
validation_prediction <- compute(nn, validation[,c(1:(length(colnames(validation))-1))])
validation_prediction_l <- validation_prediction$net.result*(max(data[output])-min(data[output]))+min(data[output])
results <- (validation[output])*(max(data[output])-min(data[output]))+min(data[output])
fitness <- (sum(results - validation_prediction_l)^2)/nrow(validation)
return(fitness)
}
evaluation("nnnn/n/n")
# https://www.analyticsvidhya.com/blog/2017/09/creating-visualizing-neural-network-in-r/
evaluation <- function(word) {
hidden_layers <- extract_neurons(word)
# https://www.rdocumentation.org/packages/neuralnet/versions/1.33/topics/neuralnet PARAMETERS
nn <- neuralnet(paste(output,input,sep="~"), data=train, hidden=hidden_layers, linear.output=T)
# https://gist.github.com/abresler/d2c324b44d7319b58309 VALIDATION
validation_prediction <- compute(nn, validation[,c(1:(length(colnames(validation))-1))])
validation_prediction_l <- validation_prediction$net.result*(max(data[output])-min(data[output]))+min(data[output])
results <- (validation[output])*(max(data[output])-min(data[output]))+min(data[output])
fitness <- (sum(results - validation_prediction_l)^2)/nrow(validation)
return(fitness)
}
evaluation("nnnn/nnn/n")
# https://www.analyticsvidhya.com/blog/2017/09/creating-visualizing-neural-network-in-r/
evaluation <- function(word) {
hidden_layers <- extract_neurons(word)
# https://www.rdocumentation.org/packages/neuralnet/versions/1.33/topics/neuralnet PARAMETERS
nn <- neuralnet(paste(output,input,sep="~"), data=train, hidden=hidden_layers, linear.output=T)
# https://gist.github.com/abresler/d2c324b44d7319b58309 VALIDATION
validation_prediction <- compute(nn, validation[,c(1:(length(colnames(validation))-1))])
validation_prediction_l <- validation_prediction$net.result*(max(data[output])-min(data[output]))+min(data[output])
results <- (validation[output])*(max(data[output])-min(data[output]))+min(data[output])
fitness <- (sum(results - validation_prediction_l)^2)/nrow(validation)
return(fitness)
}
evaluation("nnnn/nnnnn/n")
# https://www.analyticsvidhya.com/blog/2017/09/creating-visualizing-neural-network-in-r/
evaluation <- function(word) {
hidden_layers <- extract_neurons(word)
# https://www.rdocumentation.org/packages/neuralnet/versions/1.33/topics/neuralnet PARAMETERS
nn <- neuralnet(paste(output,input,sep="~"), data=train, hidden=hidden_layers, linear.output=T)
# https://gist.github.com/abresler/d2c324b44d7319b58309 VALIDATION
validation_prediction <- compute(nn, validation[,c(1:(length(colnames(validation))-1))])
validation_prediction_l <- validation_prediction$net.result*(max(data[output])-min(data[output]))+min(data[output])
results <- (validation[output])*(max(data[output])-min(data[output]))+min(data[output])
fitness <- (sum(results - validation_prediction_l)^2)/nrow(validation)
return(fitness)
}
evaluation("nnnn/nnn/nn/n")
# https://www.analyticsvidhya.com/blog/2017/09/creating-visualizing-neural-network-in-r/
evaluation <- function(word) {
hidden_layers <- extract_neurons(word)
# https://www.rdocumentation.org/packages/neuralnet/versions/1.33/topics/neuralnet PARAMETERS
nn <- neuralnet(paste(output,input,sep="~"), data=train, hidden=hidden_layers, linear.output=T)
# https://gist.github.com/abresler/d2c324b44d7319b58309 VALIDATION
validation_prediction <- compute(nn, validation[,c(1:(length(colnames(validation))-1))])
validation_prediction_l <- validation_prediction$net.result*(max(data[output])-min(data[output]))+min(data[output])
results <- (validation[output])*(max(data[output])-min(data[output]))+min(data[output])
fitness <- (sum(results - validation_prediction_l)^2)/nrow(validation)
return(fitness)
}
evaluation("nnnn/nnnnn/n")
# https://www.analyticsvidhya.com/blog/2017/09/creating-visualizing-neural-network-in-r/
evaluation <- function(word) {
hidden_layers <- extract_neurons(word)
# https://www.rdocumentation.org/packages/neuralnet/versions/1.33/topics/neuralnet PARAMETERS
nn <- neuralnet(paste(output,input,sep="~"), data=train, hidden=hidden_layers, linear.output=T)
# https://gist.github.com/abresler/d2c324b44d7319b58309 VALIDATION
validation_prediction <- compute(nn, validation[,c(1:(length(colnames(validation))-1))])
validation_prediction_l <- validation_prediction$net.result*(max(data[output])-min(data[output]))+min(data[output])
results <- (validation[output])*(max(data[output])-min(data[output]))+min(data[output])
fitness <- (sum(results - validation_prediction_l)^2)/nrow(validation)
return(fitness)
}
evaluation("nnnn/nnnn/n")
# https://www.analyticsvidhya.com/blog/2017/09/creating-visualizing-neural-network-in-r/
evaluation <- function(word) {
hidden_layers <- extract_neurons(word)
# https://www.rdocumentation.org/packages/neuralnet/versions/1.33/topics/neuralnet PARAMETERS
nn <- neuralnet(paste(output,input,sep="~"), data=train, hidden=hidden_layers, linear.output=T)
# https://gist.github.com/abresler/d2c324b44d7319b58309 VALIDATION
validation_prediction <- compute(nn, validation[,c(1:(length(colnames(validation))-1))])
validation_prediction_l <- validation_prediction$net.result*(max(data[output])-min(data[output]))+min(data[output])
results <- (validation[output])*(max(data[output])-min(data[output]))+min(data[output])
fitness <- (sum(results - validation_prediction_l)^2)/nrow(validation)
return(fitness)
}
evaluation("nnnn/nnnn/n")
# https://www.analyticsvidhya.com/blog/2017/09/creating-visualizing-neural-network-in-r/
evaluation <- function(word) {
hidden_layers <- extract_neurons(word)
# https://www.rdocumentation.org/packages/neuralnet/versions/1.33/topics/neuralnet PARAMETERS
nn <- neuralnet(paste(output,input,sep="~"), data=train, hidden=hidden_layers, linear.output=T)
# https://gist.github.com/abresler/d2c324b44d7319b58309 VALIDATION
validation_prediction <- compute(nn, validation[,c(1:(length(colnames(validation))-1))])
validation_prediction_l <- validation_prediction$net.result*(max(data[output])-min(data[output]))+min(data[output])
results <- (validation[output])*(max(data[output])-min(data[output]))+min(data[output])
fitness <- (sum(results - validation_prediction_l)^2)/nrow(validation)
return(fitness)
}
evaluation("nnnn/nnnn/n")
# https://www.analyticsvidhya.com/blog/2017/09/creating-visualizing-neural-network-in-r/
evaluation <- function(word) {
hidden_layers <- extract_neurons(word)
# https://www.rdocumentation.org/packages/neuralnet/versions/1.33/topics/neuralnet PARAMETERS
nn <- neuralnet(paste(output,input,sep="~"), data=train, hidden=hidden_layers, linear.output=T)
# https://gist.github.com/abresler/d2c324b44d7319b58309 VALIDATION
validation_prediction <- compute(nn, validation[,c(1:(length(colnames(validation))-1))])
validation_prediction_l <- validation_prediction$net.result*(max(data[output])-min(data[output]))+min(data[output])
results <- (validation[output])*(max(data[output])-min(data[output]))+min(data[output])
fitness <- (sum(results - validation_prediction_l)^2)/nrow(validation)
return(fitness)
}
evaluation("nnnn/nnnn/n")
# https://www.analyticsvidhya.com/blog/2017/09/creating-visualizing-neural-network-in-r/
evaluation <- function(word) {
hidden_layers <- extract_neurons(word)
# https://www.rdocumentation.org/packages/neuralnet/versions/1.33/topics/neuralnet PARAMETERS
nn <- neuralnet(paste(output,input,sep="~"), data=train, hidden=hidden_layers, linear.output=T)
# https://gist.github.com/abresler/d2c324b44d7319b58309 VALIDATION
validation_prediction <- compute(nn, validation[,c(1:(length(colnames(validation))-1))])
validation_prediction_l <- validation_prediction$net.result*(max(data[output])-min(data[output]))+min(data[output])
results <- (validation[output])*(max(data[output])-min(data[output]))+min(data[output])
fitness <- (sum(results - validation_prediction_l)^2)/nrow(validation)
return(fitness)
}
evaluation("nnnn/nnnn/n")
grammar <- list(
S = gsrule("<a><h>/<z>"),
a = gsrule(replicate(INPUT, "n")),
z = gsrule(replicate(OUTPUT, "n")),
h = gsrule("<h><h>", "/<n>"),
n = gsrule("n<n>", "n")
)
grammarDef <- CreateGrammar(grammar)
GrammarRandomExpression(grammarDef)
exp <- GrammarRandomExpression(grammarDef, 5)
library("gramEvol")
library("neuralnet")
data <- NULL
train <- NULL      #70%
validation <- NULL #20%
test <- NULL       #10%
input <- NULL
output <- NULL
data_cleaning <- function(url, sep){
data <<- read.csv(url, header=T, sep=sep)
colnames(data) <- gsub("[^a-zA-Z]*", "", colnames(data))
n <- nrow(data)
input <<- paste(head(colnames(data),-1), collapse="+")
output <<- paste(tail(colnames(data),1))
max <- apply(data, 2, max)
min <- apply(data, 2, min)
scaled_data <- scale(data, center=min, scale=max-min) # Normalization for numeric datasets.
shuffled_df <- as.data.frame(scaled_data[sample(n),])
train <<- shuffled_df[1:round(0.7*n),]
validation <<-  shuffled_df[(round(0.7*n)+1):round(0.9*n),]
test <<- shuffled_df[(round(0.9*n)+1):n,]
}
data_cleaning("./cereals.csv", ",")
extract_neurons <- function(word) {
layers <- strsplit(word, "/")[[1]]
i <- 0
hidden_l <- numeric(0) # Contains the number of hidden layers and the number of neurons of each hidden layer.
for(j in head(layers, -1)) {
if (i!=0) {hidden_l[i] <- nchar(j)}
i <- i+1
}
return(hidden_l)
}
# https://www.analyticsvidhya.com/blog/2017/09/creating-visualizing-neural-network-in-r/
evaluation <- function(word) {
hidden_layers <- extract_neurons(word)
# https://www.rdocumentation.org/packages/neuralnet/versions/1.33/topics/neuralnet PARAMETERS
nn <- neuralnet(paste(output,input,sep="~"), data=train, hidden=hidden_layers, linear.output=T)
# https://gist.github.com/abresler/d2c324b44d7319b58309 VALIDATION
validation_prediction <- compute(nn, validation[,c(1:(length(colnames(validation))-1))])
validation_prediction_l <- validation_prediction$net.result*(max(data[output])-min(data[output]))+min(data[output])
results <- (validation[output])*(max(data[output])-min(data[output]))+min(data[output])
fitness <- (sum(results - validation_prediction_l)^2)/nrow(validation)
return(fitness)
}
monitor <- function(results){
cat("--------------------\n")
print(results)
}
grammar <- list(
S = gsrule("<a><h>/<z>"),
a = gsrule(replicate(INPUT, "n")),
z = gsrule(replicate(OUTPUT, "n")),
h = gsrule("<h><h>", "/<n>"),
n = gsrule("n<n>", "n")
)
grammarDef <- CreateGrammar(grammar)
exp <- GrammarRandomExpression(grammarDef, 5)
grammar <- list(
S = gsrule("<a><h>/<z>"),
a = gsrule(replicate(I, "n")),
z = gsrule(replicate(O, "n")),
h = gsrule("<h><h>", "/<n>"),
n = gsrule("n<n>", "n")
)
library("gramEvol")
library("neuralnet")
data <- NULL
train <- NULL      #70%
validation <- NULL #20%
test <- NULL       #10%
input <- NULL
output <- NULL
I <- NULL
O <- NULL
data_cleaning <- function(url, sep){
data <<- read.csv(url, header=T, sep=sep)
colnames(data) <- gsub("[^a-zA-Z]*", "", colnames(data))
n <- nrow(data)
input <<- paste(head(colnames(data),-1), collapse="+")
I <<- length(colnames(data)) - 1
O <<- 1
output <<- paste(tail(colnames(data),1))
max <- apply(data, 2, max)
min <- apply(data, 2, min)
scaled_data <- scale(data, center=min, scale=max-min) # Normalization for numeric datasets.
shuffled_df <- as.data.frame(scaled_data[sample(n),])
train <<- shuffled_df[1:round(0.7*n),]
validation <<-  shuffled_df[(round(0.7*n)+1):round(0.9*n),]
test <<- shuffled_df[(round(0.9*n)+1):n,]
}
data_cleaning("./cereals.csv", ",")
extract_neurons <- function(word) {
layers <- strsplit(word, "/")[[1]]
i <- 0
hidden_l <- numeric(0) # Contains the number of hidden layers and the number of neurons of each hidden layer.
for(j in head(layers, -1)) {
if (i!=0) {hidden_l[i] <- nchar(j)}
i <- i+1
}
return(hidden_l)
}
# https://www.analyticsvidhya.com/blog/2017/09/creating-visualizing-neural-network-in-r/
evaluation <- function(word) {
hidden_layers <- extract_neurons(word)
# https://www.rdocumentation.org/packages/neuralnet/versions/1.33/topics/neuralnet PARAMETERS
nn <- neuralnet(paste(output,input,sep="~"), data=train, hidden=hidden_layers, linear.output=T)
# https://gist.github.com/abresler/d2c324b44d7319b58309 VALIDATION
validation_prediction <- compute(nn, validation[,c(1:(length(colnames(validation))-1))])
validation_prediction_l <- validation_prediction$net.result*(max(data[output])-min(data[output]))+min(data[output])
results <- (validation[output])*(max(data[output])-min(data[output]))+min(data[output])
fitness <- (sum(results - validation_prediction_l)^2)/nrow(validation)
return(fitness)
}
monitor <- function(results){
cat("--------------------\n")
print(results)
}
grammar <- list(
S = gsrule("<a><h>/<z>"),
a = gsrule(replicate(I, "n")),
z = gsrule(replicate(O, "n")),
h = gsrule("<h><h>", "/<n>"),
n = gsrule("n<n>", "n")
)
grammarDef <- CreateGrammar(grammar)
exp <- GrammarRandomExpression(grammarDef, 5)
exp <- GrammarRandomExpression(grammarDef)
grammar <- list(
S = gsrule("<a><h>/<z>"),
a = grule(replicate(I, "n")),
z = grule(replicate(O, "n")),
h = gsrule("<h><h>", "/<n>"),
n = gsrule("n<n>", "n")
)
grammarDef <- CreateGrammar(grammar)
exp <- GrammarRandomExpression(grammarDef)
exp
grammarDef
exp <- GrammarRandomExpression(grammarDef)
exp
exp <- GrammarRandomExpression(grammarDef)
exp
exp <- GrammarRandomExpression(grammarDef)
exp
exp <- GrammarRandomExpression(grammarDef)
exp
exp <- GrammarRandomExpression(grammarDef)
exp
exp <- GrammarRandomExpression(grammarDef)
exp

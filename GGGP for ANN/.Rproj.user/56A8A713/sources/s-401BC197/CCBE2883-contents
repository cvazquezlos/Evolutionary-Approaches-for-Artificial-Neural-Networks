library("gramEvol")
library("neuralnet")

INPUT = 2
OUTPUT = 3

grammar <- list(
  S = gsrule("<a><h>/<z>"),
  a = gsrule(replicate(INPUT, "n")),
  z = gsrule(replicate(OUTPUT, "n")),
  h = gsrule("<h><h>", "/<n>"),
  n = gsrule("n<n>", "n")
)

# https://datascienceplus.com/neuralnet-train-and-test-neural-networks-using-r/
# http://www.parallelr.com/r-deep-neural-network-from-scratch/
grammarDef <- CreateGrammar(grammar)
print(grammarDef)

evaluation <- function(l) {
  layers <- strsplit(l, "/")[[1]]
  i <- 0
  hidden_l <- numeric(0) # Contains the number of hidden layers and the number of neurons of each hidden layer.
  for(j in head(layers, -1)) {
    if (i!=0) {hidden_l[i] <- nchar(j)}
    i <- i+1
  }
  print(hidden_l)
  # https://medium.com/analytics-vidhya/build-your-first-neural-network-model-on-a-structured-dataset-using-keras-d9e7de5c6724
  # http://www.learnbymarketing.com/tutorials/neural-networks-in-r-tutorial/
  # Data pre-processing
  data <- read.csv("./cereals.csv", header=TRUE, sep=",")
  samplesize = 0.60 * nrow(data)
  set.seed(80)
  index <- sample(seq_len(nrow(data)), size=samplesize)
  datatrain <- data[index,]
  dataset <- data[-index,]
  max <- apply(data, 2, max)
  min <- apply(data, 2, min)
  scaled <- as.data.frame(scale(data, center=min, scale=max-min))
  trainNN <- scaled[index,]
  testNN <- scaled[-index,]
  set.seed(2)
  nn <- neuralnet(rating~calories+protein+fat+sodium+fiber, trainNN, hidden=hidden_l, linear.output=T)
  plot(nn)
}
